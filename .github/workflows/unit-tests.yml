name: Unit Tests with Excel Report

on:
  push:
    branches: [devphuctrann]

jobs:
  test:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Cache NuGet packages
        uses: actions/cache@v4
        with:
          path: ~/.nuget/packages
          key: nuget-${{ runner.os }}-${{ hashFiles('**/*.csproj') }}
          restore-keys: |
            nuget-${{ runner.os }}-

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '8.0.x'
          cache: true
          cache-dependency-path: '**/*.csproj'

      - name: Setup Python for Excel generation
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install Python dependencies
        run: |
          pip install pandas openpyxl xlsxwriter lxml beautifulsoup4

      - name: Restore dependencies
        run: dotnet restore BlindTreasure.API.sln

      - name: Build with documentation
        run: |
          dotnet build BlindTreasure.API.sln \
            --no-restore \
            --configuration Release \
            /p:GenerateDocumentationFile=true
          
          # List generated XML files to verify they exist
          find . -name "*.xml" -path "*/bin/*" | sort

      - name: Restore tools
        run: dotnet tool restore

      - name: Run unit tests
        run: |
          dotnet test BlindTreasure.API.sln \
            --no-build \
            --configuration Release \
            --verbosity normal \
            --collect:"XPlat Code Coverage" \
            --results-directory ./TestResults/ \
            --logger "trx;LogFileName=test-results.trx"

      - name: Create Excel coverage report with XML Documentation
        run: |
          mkdir -p coveragereport
          cat > generate_excel_report.py << 'EOF'
          import pandas as pd
          import json
          import xml.etree.ElementTree as ET
          from datetime import datetime
          import os
          import glob
          import re
          from bs4 import BeautifulSoup
          
          def extract_xml_documentation():
              """Tr√≠ch xu·∫•t XML documentation t·ª´ c√°c file .xml ƒë∆∞·ª£c generate"""
              # Direct path to test project XML documentation
              test_project_xml = glob.glob('./BlindTreaure.UnitTest/bin/Release/net8.0/BlindTreaure.UnitTest.xml')
              # Fallback to general search if specific file not found
              xml_files = test_project_xml if test_project_xml else glob.glob('./**/bin/**/*.xml', recursive=True)
          
              print(f"üîç Starting search for XML documentation files in bin directories")
              docs = {}
          
              print(f"üîç T√¨m th·∫•y {len(xml_files)} file XML documentation")
          
              for xml_file in xml_files:
                  try:
                      print(f"üìñ ƒêang ƒë·ªçc XML documentation t·ª´: {xml_file}")
                      tree = ET.parse(xml_file)
                      root = tree.getroot()
          
                      for member in root.findall('.//member'):
                          name = member.get('name', '')
          
                          # Ch·ªâ l·∫•y methods c√≥ ch·ª©a t·ª´ 'Test'
                          if name.startswith('M:') and 'Test' in name:
                              summary = member.find('summary')
                              remarks = member.find('remarks')
          
                              doc_info = {
                                  "summary": "",
                                  "scenario": "",
                                  "expected": "",
                                  "coverage": ""
                              }
          
                              # L·∫•y summary
                              if summary is not None and summary.text:
                                  doc_info["summary"] = summary.text.strip()
          
                              # L·∫•y chi ti·∫øt t·ª´ remarks
                              if remarks is not None and remarks.text:
                                  remarks_text = remarks.text.strip()
                                  # Parse the remarks section
                                  lines = remarks_text.split('\n')
                                  for line in lines:
                                      line = line.strip()
                                      if line.startswith("Scenario:"):
                                          doc_info["scenario"] = line.replace("Scenario:", "").strip()
                                      elif line.startswith("Expected:"):
                                          doc_info["expected"] = line.replace("Expected:", "").strip()
                                      elif line.startswith("Coverage:"):
                                          doc_info["coverage"] = line.replace("Coverage:", "").strip()
          
                              if doc_info["summary"] or doc_info["scenario"] or doc_info["expected"]:
                                  # Extract method name t·ª´ full name
                                  method_parts = name.split('.')
                                  if len(method_parts) > 0:
                                      method_name = method_parts[-1].split('(')[0]  # B·ªè parameters
          
                                      # Store both original method name and without "_Should" pattern
                                      docs[method_name] = doc_info
          
                                      # Handle special case for test methods with common patterns
                                      if "_Should" in method_name:
                                          test_parts = method_name.split('_Should')
                                          if len(test_parts) == 2:
                                              simple_name = test_parts[0]
                                              suffix = test_parts[1]
                                              docs[f"{simple_name}_Should{suffix}"] = doc_info
          
                                      print(f"üìù T√¨m th·∫•y documentation cho method: {method_name}")
          
                      print(f"‚úÖ ƒê√£ x·ª≠ l√Ω xong file: {xml_file}")
          
                  except Exception as e:
                      print(f"‚ö†Ô∏è L·ªói khi ƒë·ªçc file XML {xml_file}: {e}")
                      continue
          
              print(f"üìö T·ªïng c·ªông t√¨m th·∫•y {len(docs)} method c√≥ documentation")
              return docs
          
          def parse_cobertura_xml():
              xml_files = glob.glob('./TestResults/**/coverage.cobertura.xml', recursive=True)
              print(f"üîç Found {len(xml_files)} coverage.cobertura.xml files")
              if not xml_files:
                  return None
              tree = ET.parse(xml_files[0])
              root = tree.getroot()
              line_rate = float(root.get('line-rate', 0)) * 100
              branch_rate = float(root.get('branch-rate', 0)) * 100
              classes_data = []
              packages = root.findall('.//package')
              for package in packages:
                  package_name = package.get('name', 'Unknown')
                  classes = package.findall('.//class')
                  for cls in classes:
                      class_name = cls.get('name', 'Unknown')
                      filename = cls.get('filename', 'Unknown')
                      class_line_rate = float(cls.get('line-rate', 0)) * 100
                      class_branch_rate = float(cls.get('branch-rate', 0)) * 100
                      lines = cls.findall('.//line')
                      total_lines = len(lines)
                      covered_lines = len([l for l in lines if l.get('hits', '0') != '0'])
                      classes_data.append({
                          'Package': package_name,
                          'Class': class_name,
                          'File': filename,
                          'Line Coverage (%)': round(class_line_rate, 2),
                          'Branch Coverage (%)': round(class_branch_rate, 2),
                          'Total Lines': total_lines,
                          'Covered Lines': covered_lines,
                          'Uncovered Lines': total_lines - covered_lines
                      })
              return {
                  'summary': {
                      'line_coverage': round(line_rate, 2),
                      'branch_coverage': round(branch_rate, 2)
                  },
                  'classes': classes_data
              }
          
          def extract_test_class_name(test_name):
              """Tr√≠ch xu·∫•t t√™n class t·ª´ t√™n test"""
              parts = test_name.split('.')
              if len(parts) >= 3:
                  class_name = parts[-2]
                  if class_name.endswith('Test') or class_name.endswith('Tests'):
                      return class_name
              return 'OtherTests'
          
          def convert_to_management_name(test_class_name):
              """Chuy·ªÉn ƒë·ªïi t√™n class test th√†nh t√™n sheet Management"""
              if test_class_name.endswith('Test'):
                  base_name = test_class_name[:-4]
              elif test_class_name.endswith('Tests'):
                  base_name = test_class_name[:-5]
              else:
                  base_name = test_class_name
          
              if base_name.endswith('Service'):
                  base_name = base_name[:-7]
          
              return f"{base_name}Management"
          
          def get_test_description_from_name(test_method):
              """T·∫°o m√¥ t·∫£ t·ª´ t√™n ph∆∞∆°ng th·ª©c test (fallback)"""
              if '_' in test_method:
                  words = test_method.split('_')
                  return 'Test method: ' + ' '.join(words)
          
              words = re.findall(r'[A-Z](?:[a-z]+|[A-Z]*(?=[A-Z]|$))', test_method)
              if words:
                  return 'Test method: ' + ' '.join(words)
          
              return 'Test method: ' + test_method
          
          def get_enhanced_description(test_method, xml_docs):
              """L·∫•y m√¥ t·∫£ t·ª´ XML documentation ho·∫∑c fallback v·ªÅ t√™n method"""
              # Format documentation text to be a clean paragraph
              def format_text(text):
                  # Remove line breaks, extra spaces and normalize whitespace
                  if text is None:
                      return ""
                  clean_text = ' '.join(text.replace('\n', ' ').replace('\r', ' ').split())
                  # Limit text length for Excel cell
                  if len(clean_text) > 300:
                      clean_text = clean_text[:297] + "..."
                  return clean_text
          
              # Default empty result
              result = {
                  "description": "",
                  "procedure": "",
                  "expected": ""
              }
          
              # T√¨m trong XML documentation tr∆∞·ªõc
              if test_method in xml_docs:
                  doc_info = xml_docs[test_method]
                  result["description"] = format_text(doc_info.get("summary", ""))
                  result["procedure"] = format_text(doc_info.get("scenario", ""))
                  result["expected"] = format_text(doc_info.get("expected", ""))
                  return result
          
              # Try alternate name formats for better matching with test method names
              # For methods like "GetByIdAsync_ShouldReturnEntity_WhenEntityExists"
              if "_Should" in test_method:
                  parts = test_method.split("_Should")
                  if len(parts) >= 2:
                      # Try matching with the base method name
                      base_name = parts[0]
                      if base_name in xml_docs:
                          doc_info = xml_docs[base_name]
                          result["description"] = format_text(doc_info.get("summary", ""))
                          result["procedure"] = format_text(doc_info.get("scenario", ""))
                          result["expected"] = format_text(doc_info.get("expected", ""))
                          return result
          
              # Look through all keys in xml_docs for potential match
              for doc_key in xml_docs.keys():
                  # Check if the test method is a substring of a documented method
                  # or if a documented method is a substring of the test method
                  if test_method in doc_key or doc_key in test_method:
                      doc_info = xml_docs[doc_key]
                      result["description"] = format_text(doc_info.get("summary", ""))
                      result["procedure"] = format_text(doc_info.get("scenario", ""))
                      result["expected"] = format_text(doc_info.get("expected", ""))
                      return result
          
              # Fallback v·ªÅ m√¥ t·∫£ t·ª´ t√™n method
              fallback_desc = get_test_description_from_name(test_method)
              result["description"] = format_text(fallback_desc)
              # Extract expected results from method name if possible
              if "_Should" in test_method and "_When" in test_method:
                  parts = test_method.split("_Should")
                  if len(parts) > 1:
                      expected_part = parts[1].split("_When")[0]
                      result["expected"] = format_text(f"Should {expected_part}")
          
                  when_parts = test_method.split("_When")
                  if len(when_parts) > 1:
                      procedure_part = when_parts[1]
                      result["procedure"] = format_text(f"When {procedure_part}")
          
              return result
          
          def parse_test_results():
              trx_files = glob.glob('./TestResults/**/test-results.trx', recursive=True)
              test_data_by_class = {}
              xml_docs = extract_xml_documentation()  # L·∫•y XML documentation
          
              if trx_files:
                  try:
                      with open(trx_files[0], 'r', encoding='utf-8') as f:
                          content = f.read()
                          soup = BeautifulSoup(content, 'xml')
                      test_results = soup.find_all('UnitTestResult')
          
                      for result in test_results:
                          test_name = result.get('testName', 'Unknown')
                          outcome = result.get('outcome', 'Unknown')
                          duration = result.get('duration', '00:00:00')
          
                          error_info = result.find('ErrorInfo')
                          error_message = ""
                          if error_info:
                              message_elem = error_info.find('Message')
                              if message_elem:
                                  error_message = message_elem.get_text()
          
                          # L·∫•y t√™n ph∆∞∆°ng th·ª©c test t·ª´ testName
                          test_method = test_name.split('.')[-1]
          
                          # L·∫•y t√™n class test v√† chuy·ªÉn ƒë·ªïi th√†nh t√™n sheet Management
                          test_class = extract_test_class_name(test_name)
                          sheet_name = convert_to_management_name(test_class)
          
                          # S·ª≠ d·ª•ng enhanced description v·ªõi XML documentation
                          description_data = get_enhanced_description(test_method, xml_docs)
          
                          # T·∫°o ƒë·ªëi t∆∞·ª£ng test case v·ªõi th√¥ng tin chi ti·∫øt
                          test_case = {
                              'ID': f"TC_{len(test_data_by_class.get(sheet_name, [])) + 1:03d}",
                              'Test Method': test_method,
                              'Test Case Description': description_data["description"],
                              'Test Case Procedure': description_data["procedure"],
                              'Expected Results': description_data["expected"] or "Test should pass successfully",
                              'Actual Result': outcome,
                              'Status': 'Pass' if outcome == 'Passed' else 'Fail',
                              'Duration': duration,
                              'Error Message': error_message if error_message else 'N/A'
                          }
          
                          if sheet_name not in test_data_by_class:
                              test_data_by_class[sheet_name] = []
          
                          test_data_by_class[sheet_name].append(test_case)
          
                  except Exception as e:
                      print(f"‚ùå Error parsing TRX file: {e}")
          
              return test_data_by_class
          
          def create_excel_report():
              print("üöÄ B·∫Øt ƒë·∫ßu t·∫°o Excel report...")
          
              coverage_data = parse_cobertura_xml()
              test_data_by_class = parse_test_results()
              timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
              excel_file = f'./coveragereport/Coverage_Report_{timestamp}.xlsx'
          
              with pd.ExcelWriter(excel_file, engine='xlsxwriter') as writer:
                  workbook = writer.book
          
                  # ƒê·ªãnh d·∫°ng cho c√°c header v√† cell
                  header_format = workbook.add_format({
                      'bold': True,
                      'text_wrap': True,
                      'valign': 'top',
                      'fg_color': '#4472C4',
                      'font_color': 'white',
                      'border': 1
                  })
          
                  cell_format = workbook.add_format({
                      'text_wrap': True,
                      'valign': 'top',
                      'border': 1
                  })
          
                  pass_format = workbook.add_format({
                      'text_wrap': True,
                      'valign': 'top',
                      'border': 1,
                      'bg_color': '#E2EFDA'
                  })
          
                  fail_format = workbook.add_format({
                      'text_wrap': True,
                      'valign': 'top',
                      'border': 1,
                      'bg_color': '#FFE6E6'
                  })
          
                  # Standard format for descriptions
                  description_format = workbook.add_format({
                      'text_wrap': True,
                      'valign': 'top',
                      'border': 1
                  })
          
                  # T·∫°o sheet Summary
                  summary_data = []
                  if coverage_data:
                      total_tests = sum(len(tests) for tests in test_data_by_class.values())
                      passed_tests = sum(len([t for t in tests if t['Status'] == 'Pass']) for tests in test_data_by_class.values())
                      # Count tests that have documentation (not using emojis anymore)
                      xml_doc_tests = sum(len([t for t in tests if 'Description' in t and t['Description']]) for tests in test_data_by_class.values())
          
                      summary_data = [
                          ['Metric', 'Value', 'Status'],
                          ['Line Coverage', f"{coverage_data['summary']['line_coverage']}%", 
                           'Pass' if coverage_data['summary']['line_coverage'] >= 70 else 'Fail'],
                          ['Branch Coverage', f"{coverage_data['summary']['branch_coverage']}%", ''],
                          ['Total Tests', total_tests, ''],
                          ['Passed Tests', passed_tests, ''],
                          ['Failed Tests', total_tests - passed_tests, ''],
                          ['Tests with Documentation', xml_doc_tests, f'{(xml_doc_tests/total_tests*100):.0f}%' if total_tests > 0 else '0%'],
                          ['Test Pass Rate', f"{(passed_tests / total_tests * 100) if total_tests > 0 else 0:.2f}%", ''],
                          ['Test Run Date', datetime.now().strftime("%Y-%m-%d %H:%M:%S"), ''],
                          ['Minimum Coverage Threshold', '70%', ''],
                      ]
                  else:
                      summary_data = [
                          ['Metric', 'Value', 'Status'],
                          ['Line Coverage', 'N/A', 'No data available'],
                      ]
          
                  df_summary = pd.DataFrame(summary_data[1:], columns=summary_data[0])
                  df_summary.to_excel(writer, sheet_name='Summary', index=False)
                  worksheet_summary = writer.sheets['Summary']
                  worksheet_summary.set_column('A:A', 25)
                  worksheet_summary.set_column('B:B', 20)
                  worksheet_summary.set_column('C:C', 15)
          
                  for row_num in range(len(df_summary) + 1):
                      for col_num in range(len(df_summary.columns)):
                          if row_num == 0:
                              worksheet_summary.write(row_num, col_num, df_summary.columns[col_num], header_format)
                          else:
                              worksheet_summary.write(row_num, col_num, df_summary.iloc[row_num-1, col_num], cell_format)
          
                  # T·∫°o sheet Coverage Details
                  if coverage_data and coverage_data['classes']:
                      df_classes = pd.DataFrame(coverage_data['classes'])
                      df_classes.to_excel(writer, sheet_name='Coverage Details', index=False)
                      worksheet_details = writer.sheets['Coverage Details']
                      worksheet_details.set_column('A:A', 25)
                      worksheet_details.set_column('B:B', 30)
                      worksheet_details.set_column('C:C', 40)
                      worksheet_details.set_column('D:D', 18)
                      worksheet_details.set_column('E:E', 18)
                      worksheet_details.set_column('F:F', 12)
                      worksheet_details.set_column('G:G', 15)
                      worksheet_details.set_column('H:H', 15)
          
                      for row_num in range(len(df_classes) + 1):
                          for col_num in range(len(df_classes.columns)):
                              if row_num == 0:
                                  worksheet_details.write(row_num, col_num, df_classes.columns[col_num], header_format)
                              else:
                                  worksheet_details.write(row_num, col_num, df_classes.iloc[row_num-1, col_num], cell_format)
          
                  # T·∫°o c√°c sheet cho t·ª´ng class test v·ªõi enhanced formatting
                  for sheet_name, test_cases in test_data_by_class.items():
                      if len(sheet_name) > 31:
                          sheet_name = sheet_name[:28] + "..."
          
                      df_tests = pd.DataFrame(test_cases)
                      df_tests.to_excel(writer, sheet_name=sheet_name, index=False)
          
                      worksheet = writer.sheets[sheet_name]
                      worksheet.set_column('A:A', 10)  # ID
                      worksheet.set_column('B:B', 30)  # Test Method
                      worksheet.set_column('C:C', 40)  # Test Case Description
                      worksheet.set_column('D:D', 40)  # Test Case Procedure
                      worksheet.set_column('E:E', 40)  # Expected Results
                      worksheet.set_column('F:F', 15)  # Actual Result
                      worksheet.set_column('G:G', 15)  # Status
                      worksheet.set_column('H:H', 15)  # Duration
                      worksheet.set_column('I:I', 40)  # Error Message
          
                      for row_num in range(len(df_tests) + 1):
                          for col_num in range(len(df_tests.columns)):
                              if row_num == 0:
                                  worksheet.write(row_num, col_num, df_tests.columns[col_num], header_format)
                              else:
                                  cell_value = df_tests.iloc[row_num-1, col_num]
          
                                  # √Åp d·ª•ng ƒë·ªãnh d·∫°ng kh√°c nhau d·ª±a tr√™n n·ªôi dung
                                  if col_num == 5:  # Status column
                                      if str(cell_value) == 'Pass':
                                          worksheet.write(row_num, col_num, cell_value, pass_format)
                                      else:
                                          worksheet.write(row_num, col_num, cell_value, fail_format)
                                  elif col_num == 2:  # Description column
                                      worksheet.write(row_num, col_num, cell_value, description_format)
                                  else:
                                      worksheet.write(row_num, col_num, cell_value, cell_format)
          
              print(f"‚úÖ Excel report generated: {excel_file}")
              return excel_file
          
          if __name__ == "__main__":
              excel_file = create_excel_report()
          EOF
          python generate_excel_report.py
      
      - name: Upload Excel coverage reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: excel-coverage-report-with-docs
          path: ./coveragereport/Coverage_Report_*.xlsx
          retention-days: 30