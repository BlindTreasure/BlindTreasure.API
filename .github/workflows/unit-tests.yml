name: Unit Tests with Excel Report (Functions + Statistics + Matrices)

on:
  push:
    branches: [devphuctrann]

jobs:
  test:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Cache NuGet packages
        uses: actions/cache@v4
        with:
          path: ~/.nuget/packages
          key: nuget-${{ runner.os }}-${{ hashFiles('**/*.csproj') }}
          restore-keys: |
            nuget-${{ runner.os }}-

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '8.0.x'
          cache: true
          cache-dependency-path: '**/*.csproj'

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install Python dependencies
        run: |
          pip install pandas openpyxl xlsxwriter lxml beautifulsoup4

      - name: Restore dependencies
        run: dotnet restore BlindTreasure.API.sln

      - name: Build with XML docs
        run: |
          dotnet build BlindTreasure.API.sln \
            --no-restore \
            --configuration Release \
            /p:GenerateDocumentationFile=true
          find ./BlindTreasure.UnitTest/bin -name "*.xml" | sort || true

      - name: Run unit tests with coverage
        run: |
          dotnet test BlindTreasure.API.sln \
            --no-build \
            --configuration Release \
            --verbosity normal \
            --collect:"XPlat Code Coverage" \
            --results-directory ./TestResults/ \
            --logger "trx;LogFileName=test-results.trx"
          find ./TestResults -name "test-results.trx" | sort || true

      - name: Generate Excel Report (Functions + Statistics + Matrices)
        run: |
          mkdir -p coveragereport
          cat > generate_excel_report.py << 'EOF'
          import pandas as pd
          import xml.etree.ElementTree as ET
          from bs4 import BeautifulSoup
          from collections import defaultdict
          import glob, re

          XML_PREFIX = "M:BlindTreasure.UnitTest.Services."

          # ---------- helpers ----------
          def strip_params(s): return s.split('(')[0] if s else s
          def short_class(fq): return fq.split('.')[-1] if fq else ''
          def norm(s): return re.sub(r'[^A-Za-z0-9_]', '', (s or '')).lower()

          def base_function_from_test(method_name: str) -> str:
              """Lấy function-under-test từ test method: RegisterCustomerAsync_Should... -> RegisterCustomerAsync"""
              m = strip_params(method_name or '')
              if '_Should' in m: return m.split('_Should',1)[0]
              if '_When'   in m: return m.split('_When',1)[0]
              return m

          def same_function(doc_func: str, test_method: str) -> bool:
              d = norm(doc_func); t = norm(base_function_from_test(test_method))
              return d == t

          def classify_case(name: str) -> str:
              n = (name or '').lower()
              if 'boundary' in n: return 'B'
              if 'abnormal' in n: return 'A'
              if 'normal'   in n: return 'N'
              return 'N'

          def expected_from_name(name: str) -> str:
              n = (name or '').lower()
              if 'shouldreturntrue'  in n or 'should_be_true' in n:  return 'TRUE'
              if 'shouldreturnfalse' in n or 'should_be_false' in n: return 'FALSE'
              if 'shouldthrow' in n or 'exception' in n: return 'EXCEPTION'
              return ''

          def extract_log_message_from_name(name: str) -> str:
              """Extract expected log message or error from test name"""
              n = (name or '').lower()
              if 'conflict' in n: return 'Conflict error'
              if 'forbidden' in n: return 'Forbidden access'
              if 'notfound' in n: return 'Not found error'
              if 'badrequest' in n: return 'Bad request error'
              if 'unauthorized' in n: return 'Unauthorized access'
              return ''

          def to_conditions_from_name(name: str):
              """Parse điều kiện từ phần _When... của tên test."""
              base = strip_params(name or '')
          
              # Parse from test method name structure
              conditions = []
          
              # Common patterns in test names
              if 'validdata' in base.lower() or 'shouldcreate' in base.lower() or 'shouldupdate' in base.lower():
                  conditions.append('Valid input data')
          
              if 'invalid' in base.lower() or 'empty' in base.lower() or 'null' in base.lower():
                  conditions.append('Invalid or empty input')
          
              if 'notexists' in base.lower() or 'notfound' in base.lower():
                  conditions.append('Entity does not exist')
          
              if 'notadmin' in base.lower() or 'notauthorized' in base.lower() or 'forbidden' in base.lower():
                  conditions.append('User not authorized')
          
              if 'nameexists' in base.lower() or 'conflict' in base.lower():
                  conditions.append('Name already exists')
          
              if 'hasproducts' in base.lower() or 'haschildren' in base.lower():
                  conditions.append('Has dependent entities')
          
              if 'nochildren' in base.lower() or 'validandno' in base.lower():
                  conditions.append('No dependent entities')

              # If no conditions found from name, try to parse _When part
              if not conditions and '_When' in base:
                  cond = base.split('_When',1)[1]
                  parts = [p for p in re.split(r'_And_|_', cond) if p]
                  for p in parts:
                      s = re.sub(r'([a-z0-9])([A-Z])', r'\1 \2', p).replace('_',' ').strip()
                      s = s.replace('Api Key','API key').replace('Null Or','null or').replace(' Is ',' is ')
                      conditions.append(s[0].upper()+s[1:] if s else s)
          
              return conditions[:3]  # Limit to 3 conditions max

          def safe_sheet_name(name, existing_sheets):
              """Create a safe Excel sheet name (max 31 chars, unique)"""
              if not name:
                  name = "Sheet"
          
              # Clean invalid characters for Excel sheet names
              safe_name = re.sub(r'[\\/*\[\]:?]', '_', str(name))
          
              # Truncate to fit within Excel's 31 character limit, leaving room for suffix
              max_base_length = 25  # Leave room for " (999)" suffix
              if len(safe_name) > max_base_length:
                  safe_name = safe_name[:max_base_length]
          
              # Handle duplicates
              final_name = safe_name
              counter = 1
              while final_name in existing_sheets:
                  counter += 1
                  suffix = f" ({counter})"
                  # Ensure total length doesn't exceed 31 characters
                  if len(safe_name) + len(suffix) > 31:
                      truncated = safe_name[:31-len(suffix)]
                      final_name = f"{truncated}{suffix}"
                  else:
                      final_name = f"{safe_name}{suffix}"
          
              return final_name

          # ---------- XML -> functions (group by class + function-under-test) ----------
          def extract_functions():
              xml_files = glob.glob('./BlindTreasure.UnitTest/bin/**/*.xml', recursive=True)
              agg = {}  # key=(Class, Func) -> data
              for f in xml_files:
                  try:
                      root = ET.parse(f).getroot()
                  except Exception:
                      continue
                  for m in root.findall('.//member'):
                      name = m.get('name','')
                      if not name.startswith('M:'): continue
                      if not name.startswith(XML_PREFIX): continue
                      parts = name.split('.')
                      if len(parts) < 2: continue
                      cls = parts[-2]
                      test_method = strip_params(parts[-1])
                      func = base_function_from_test(test_method)

                      desc = ''
                      pre  = ''
                      cov  = ''
                      s = m.find('summary')
                      if s is not None and s.text: desc = ' '.join(s.text.split())
                      r = m.find('remarks')
                      if r is not None and r.text:
                          for line in r.text.splitlines():
                              line=line.strip()
                              if line.startswith('Scenario:'): pre = line.replace('Scenario:','').strip() or pre
                              elif line.startswith('Coverage:'): cov = line.replace('Coverage:','').strip() or cov

                      key=(cls,func)
                      if key not in agg:
                          agg[key]={"Class":cls,"Function":func,"Description":desc,"PreCondition":pre,"Requirement":cov}
                      else:
                          if not agg[key]["Description"] and desc: agg[key]["Description"]=desc
                          if not agg[key]["PreCondition"] and pre: agg[key]["PreCondition"]=pre
                          if not agg[key]["Requirement"] and cov:  agg[key]["Requirement"]=cov
              return list(agg.values())

          # ---------- TRX robust parse ----------
          def parse_trx():
              trx_files = glob.glob('./TestResults/**/test-results.trx', recursive=True)
              if not trx_files: return []
              with open(trx_files[0],'r',encoding='utf-8') as f:
                  soup = BeautifulSoup(f.read(),'xml')

              id_map={}
              for ut in soup.find_all('UnitTest'):
                  ut_id = ut.get('id') or ut.get('testId')
                  tm = ut.find('TestMethod')
                  if not ut_id or tm is None: continue
                  class_full = tm.get('className','')
                  method_name = strip_params(tm.get('name',''))
                  id_map[ut_id]=(short_class(class_full), method_name)

              out=[]
              for res in soup.find_all('UnitTestResult'):
                  tid = res.get('testId')
                  if not tid or tid not in id_map: continue
                  cls, mth = id_map[tid]
                  out.append({
                      "Class": cls,
                      "Method": mth,               # test method name
                      "Base": base_function_from_test(mth),  # function-under-test
                      "Outcome": res.get('outcome','Unknown'),
                      "Display": strip_params(res.get('testName','')),
                      "ExecutedAt": res.get('endTime') or res.get('startTime') or ''
                  })
              return out

          # ---------- Build "Functions" & "Statistics" ----------
          def build_core():
              funcs = extract_functions()
              trx = parse_trx()

              # Index TRX by (Class, Base)
              idx = defaultdict(list)
              for t in trx:
                  idx[(t["Class"], t["Base"])].append(t)

              # Sheet 1: Functions (Sheet Name = function)
              func_rows=[]
              for i,f in enumerate(funcs,1):
                  func_rows.append({
                      "No": i,
                      "RequirementName": f["Requirement"],
                      "Class Name": f["Class"],
                      "Function Name": f["Function"],
                      "Function Code": f"Code_{i}",
                      "Sheet Name": f["Function"],   # yêu cầu: đúng bằng method
                      "Description": f["Description"],
                      "Pre-Condition": f["PreCondition"]
                  })

              # Sheet 2: Statistics (aggregate theo function)
              stat_rows=[]
              for i,f in enumerate(funcs,1):
                  tests = idx.get((f["Class"], f["Function"]), [])
                  p=f_=u=0; N=A=B=0
                  for t in tests:
                      if t["Outcome"]=="Passed": p+=1
                      elif t["Outcome"]=="Failed": f_+=1
                      else: u+=1
                      c = classify_case(t["Display"] or t["Method"])
                      if c=='N': N+=1
                      elif c=='A': A+=1
                      elif c=='B': B+=1
                  stat_rows.append({
                      "No": i,
                      "Function Code": f'=HYPERLINK("#{f["Function"]}!A1","Code_{i}")',
                      "Passed": p, "Failed": f_, "Untested": u,
                      "N": N, "A": A, "B": B,
                      "Total Test Cases": p+f_+u
                  })

              return funcs, pd.DataFrame(func_rows), pd.DataFrame(stat_rows), idx

          # ---------- Matrix writer (per function) ----------
          def write_matrix(workbook, writer, func, tests):
              # Create safe sheet name that respects Excel's 31 character limit
              sheet_name = safe_sheet_name(func["Function"], writer.sheets.keys())
              ws = workbook.add_worksheet(sheet_name)
              writer.sheets[sheet_name] = ws

              # Define formats following the sample image
              # Blue header format for UTCID columns
              blue_header = workbook.add_format({
                  "bold": True,
                  "align": "center",
                  "valign": "vcenter",
                  "border": 1,
                  "bg_color": "#1e1b4b",
                  "font_color": "white",
                  "rotation": 90  # Vertical text like in the image
              })
          
              # Blue section headers (Condition, Confirm, Result)
              blue_section = workbook.add_format({
                  "bold": True,
                  "align": "center",
                  "valign": "vcenter",
                  "border": 1,
                  "bg_color": "#1e1b4b",
                  "font_color": "white"
              })
          
              # Regular label format
              label_format = workbook.add_format({
                  "align": "left",
                  "valign": "vcenter",
                  "border": 1
              })
          
              # Data cell format (white background with border)
              data_format = workbook.add_format({
                  "align": "center",
                  "valign": "vcenter",
                  "border": 1
              })
          
              # Special format for return values (FALSE, TRUE)
              return_label_format = workbook.add_format({
                  "align": "right",
                  "valign": "vcenter",
                  "border": 1,
                  "font_size": 8
              })

              # Process test data
              cols = []
              for k,t in enumerate(tests,1):
                  cols.append({
                      "id": f"UTCID{k:02d}",
                      "name": t["Display"] or t["Method"],
                      "exp": expected_from_name(t["Display"] or t["Method"]),
                      "type": classify_case(t["Display"] or t["Method"]),
                      "out": t["Outcome"],
                      "dt": t["ExecutedAt"],
                      "conds": to_conditions_from_name(t["Display"] or t["Method"]),
                      "log_msg": extract_log_message_from_name(t["Display"] or t["Method"])
                  })

              # Get unique conditions
              all_conditions = []
              for c in cols:
                  for cond in c["conds"]:
                      if cond and cond not in all_conditions:
                          all_conditions.append(cond)
          
              if not all_conditions:
                  all_conditions = ["No specific condition"]

              # Set column widths
              ws.set_column(0, 0, 35)  # Label column
              for j in range(len(cols)):
                  ws.set_column(1+j, 1+j, 4)  # Narrow columns for test data

              r = 0
          
              # Header row with UTCID columns (vertical text)
              ws.write(r, 0, "", data_format)
              for j, c in enumerate(cols):
                  ws.write(r, 1+j, c["id"], blue_header)
              r += 1

              # Calculate section sizes to avoid overlap
              condition_rows = 2 + len(all_conditions)  # Precondition + input conditions
              confirm_rows = 5  # Return + FALSE + TRUE + Exception + Log message  
              result_rows = 4   # Type + Passed/Failed + Executed Date + Defect ID

              # CONDITION section
              condition_start = r
              condition_end = condition_start + condition_rows - 1
              ws.merge_range(condition_start, 0, condition_end, 0, "Condition", blue_section)
          
              # Precondition row
              ws.write(condition_start + 1, 0, "Precondition", label_format)
              for j in range(len(cols)):
                  ws.write(condition_start + 1, 1+j, "", data_format)
          
              # Input conditions
              for i, condition in enumerate(all_conditions):
                  row = condition_start + 2 + i
                  ws.write(row, 0, f"Input: {condition}", label_format)
                  for j, c in enumerate(cols):
                      val = "O" if condition in c["conds"] else ""
                      ws.write(row, 1+j, val, data_format)
          
              r = condition_end + 1

              # CONFIRM section
              confirm_start = r
              confirm_end = confirm_start + confirm_rows - 1
              ws.merge_range(confirm_start, 0, confirm_end, 0, "Confirm", blue_section)
          
              # Return subsection
              ws.write(confirm_start + 1, 0, "Return", label_format)
          
              # FALSE row
              ws.write(confirm_start + 2, 0, "FALSE", return_label_format)
              for j, c in enumerate(cols):
                  val = "O" if c["exp"] == "FALSE" else ""
                  ws.write(confirm_start + 2, 1+j, val, data_format)
          
              # TRUE row  
              ws.write(confirm_start + 3, 0, "TRUE", return_label_format)
              for j, c in enumerate(cols):
                  val = "O" if c["exp"] == "TRUE" else ""
                  ws.write(confirm_start + 3, 1+j, val, data_format)
          
              # Exception subsection
              ws.write(confirm_start + 4, 0, "Exception", label_format)
          
              # Log message row
              ws.write(confirm_start + 5, 0, "Log message", label_format)
              for j, c in enumerate(cols):
                  msg = c["log_msg"] if c["exp"] == "EXCEPTION" else ""
                  ws.write(confirm_start + 5, 1+j, msg, data_format)
          
              r = confirm_end + 1

              # RESULT section
              result_start = r
              result_end = result_start + result_rows - 1
              ws.merge_range(result_start, 0, result_end, 0, "Result", blue_section)
          
              # Type row
              ws.write(result_start + 1, 0, "Type(N : Normal, A : Abnormal, B : Boundary)", label_format)
              for j, c in enumerate(cols):
                  ws.write(result_start + 1, 1+j, c["type"], data_format)
          
              # Passed/Failed row
              ws.write(result_start + 2, 0, "Passed/Failed", label_format)
              for j, c in enumerate(cols):
                  result_val = "P" if c["out"] == "Passed" else ("F" if c["out"] == "Failed" else "")
                  ws.write(result_start + 2, 1+j, result_val, data_format)
          
              # Executed Date row
              ws.write(result_start + 3, 0, "Executed Date", label_format)
              for j, c in enumerate(cols):
                  date_str = c["dt"].split('T')[0] if 'T' in c["dt"] else c["dt"]
                  ws.write(result_start + 3, 1+j, date_str, data_format)
          
              # Defect ID row
              ws.write(result_start + 4, 0, "Defect ID", label_format)
              for j in range(len(cols)):
                  ws.write(result_start + 4, 1+j, "", data_format)

              return sheet_name

          # ---------- main ----------
          def main():
              funcs, df_funcs, df_stats, idx = build_core()
              out = "./coveragereport/Functions_Statistics_Report.xlsx"
          
              # Track actual sheet names created (for hyperlink updates)
              sheet_name_mapping = {}
          
              with pd.ExcelWriter(out, engine="xlsxwriter") as w:
                  # Core sheets
                  df_funcs.to_excel(w, sheet_name="Functions", index=False)
                  df_stats.to_excel(w, sheet_name="Statistics", index=False)

                  wb = w.book
                  hdr = wb.add_format({"bold": True,"bg_color":"#1F4E78","font_color":"white","border":1})
          
                  for sheet,df in [("Functions",df_funcs),("Statistics",df_stats)]:
                      ws = w.sheets[sheet]
                      for c,col in enumerate(df.columns):
                          ws.write(0,c,col,hdr)

                  # Matrix per function
                  for f in funcs:
                      tests = idx.get((f["Class"], f["Function"]), [])
                      if tests:  # Only create matrix if there are tests
                          actual_sheet_name = write_matrix(wb, w, f, tests)
                          sheet_name_mapping[f["Function"]] = actual_sheet_name

                  # Update hyperlinks in Statistics sheet
                  stats_ws = w.sheets["Statistics"]
                  for i, f in enumerate(funcs):
                      if f["Function"] in sheet_name_mapping:
                          actual_name = sheet_name_mapping[f["Function"]]
                          hyperlink_formula = f'=HYPERLINK("#{actual_name}!A1","Code_{i+1}")'
                          stats_ws.write(i+1, 1, hyperlink_formula)

              print(f"Report generated: {out}")

          if __name__ == "__main__":
              main()
          EOF
          python generate_excel_report.py

      - name: Upload Excel coverage reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: excel-functions-statistics-report
          path: ./coveragereport/Functions_Statistics_Report.xlsx
          retention-days: 30